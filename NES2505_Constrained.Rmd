---
title: "Constrained analyses"
output: learnr::tutorial
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
library(learnr)
library(mosaic)
library(vegan)
library(ggrepel)
data(dune)
data(dune.env)
data(varespec)
data(varechem)
knitr::opts_chunk$set(echo = FALSE)
```


## Multiple responses plus explanatory variables
### Introduction
Unconstrained ordination methods such as PCA, CA and NMDS allow you to summarise
the relationships between your samples (sites, isolates, quadrats etc.) and your
attributes (species, gene sequences etc.). They provide a useful method to 
simplify your data so that it can be viewed in a 2-dimensional ordination plot.
The scores from these plots, especially the first axis, can sometimes be related
to potential explanatory variables to aid interpretation, as you showed with
soil moisture and the dune vegetation analysis. Within these interactive webpages, we are going to look at constrained ordination but first we think about indirect gradient analysis.

### Indirect gradient analysis

If you have explanatory variables, you might be tempted to extract an ordination
axis, and after visualising any patterns with a potential explanatory variable,
undertake a linear model, with your chosen **ordination axis** as your response.
For example, recall that you undertook a PCA of the sand dune vegetation data,
and showed a clear pattern with Moisture:

```{r dune_pca, echo=TRUE}
# PCA of dune data
dune_pca <- rda(dune)

# Plot of PC1 vs PC2
plot(dune_pca, type = "n")
text(dune_pca, display = "sites", cex = 0.7)

# Extract PC1 and relate to soil moisture category
dune_pc1 <- scores(dune_pca, display="sites", choices = 1)
gf_boxplot(dune_pc1 ~ Moisture, data=dune.env)%>%
  gf_theme(theme_classic())
```

Now let's do a linear model to formally test the relationship between soil
moisture and dune vegetation composition as described by PC1. We'll display
the ANOVA table, and check the first two model diagnostic plots (residuals and
QQ plots) via the `mplot()` function:

```{r dune_pca_lm-setup}
dune_pca <- rda(dune)
dune_pc1 <- scores(dune_pca, display="sites", choices = 1)

```

```{r dune_pca_lm, exercise=TRUE}
dune_lm <- lm(dune_pc1 ~ Moisture, data=dune.env)
anova(dune_lm)
mplot(dune_lm, which=1:2)

```

The relationship with moisture class is highly significant, with F=14.94426 and
p=6.691419e-05 which is p=0.00006691419 (**remember** you would report these as
"F=14.94, p<0.001"). There are no obvious problems with the residuals vs fitted
plot, with an even scatter around the zero line. The QQ plot looks good, with
most points along the expected diagonal line.

When techniques to handle lots of response variables were first developed, this
was the most common method of analysis. It is sometimes referred to as **indirect gradient analysis**
and was widely used until the 1990's.

## Problems with indirect gradient analysis
The linear model presented on the previous page showed no obvious problems, so
the disadvantages of indirect gradient analysis may not be immediately obvious.
However, one assumption of linear models (and GLMs), is that all your response
data points are independent of each other:

* The composition of plants in your first quadrat should not affect those in your second. 
* The gene sequence from your third isolate should not change those in your fifth
* The bacterial OTU samples from Chile should be independent of the OTUs obtained from France
* The types of insects found in your pitfall trap sample from Northumberland should
not influence those found in your pitfall trap from Cornwall

This seems fairly obvious, and in practical terms, when you collect the data from
field surveys or laboratory experiments, the various samples are independent. The
problem arises from what happens when you undertake an unconstrained ordination.

### Non-independence of ordination scores
Let's repeat our PCA of the sand dune vegetation, but omit one of the samples
at random (sample 6):

```{r compare_pca}
dune_pca <- rda(dune)
dune_pca_no6 <- rda(dune[-6,])
dune_plt1 <- plot(dune_pca, display="sites", main="PCA with full dataset")
dune_plt2 <- plot(dune_pca_no6, display="sites", main="PCA with one sample omitted")

```

You can see that the whole ordination has 'flipped' on its vertical axis. Depending
on your data, sometimes both PC1 and PC2 will flip or rotate. The relative positions
of the samples are still roughly the same. The samples which are similar in their species
composition (e.g. 17, 18 and 19) are still relatively close to each other, but they
have nevertheless moved.

**Key point**

Whilst your original quadrats, isolates, samples or sites may have been independent
from each other, once they are converted to PCA axis scores, the actual scores are
**not** independent. Fortunately, an alternative method to resolve this problem,
known as **constrained ordination** was developed in 1989, and has since become
a standard technique for biologists.

## Constrained ordination
In a constrained ordination the explanatory variables (categorical and/or
continuous) are incorporated into the ordination itself. The sample scores are
constrained to be linear combinations of the various explanatory variables,
whilst simultaneously accounting for the composition of the attributes. So the
overall format is:

$$\text{Table of response variables} = \text{Explanatory variables} + \epsilon$$

Note that the technique does not work effectively if you only have one or two
explanatory variables, as it may constrain all your samples or attributes too
much along one axis. The display of constrained analysis is in the form of 
modified ordination plots, which can be very informative once you have learnt
how to interpret them. You can also undertake formal statistical tests using
analyses analogous to ANOVA. The technique will also cope with complex experimental
designs, such as blocked designs, or time-series. You can also create interaction
terms if needed.

Constrained analysis exists in two main forms, linear and unimodal. The linear
form is Redundancy Analysis (RDA) and unimodal is Canonical Correspondence Analysis
(CCA). These are run using the `rda()` and `cca()` functions respectively, which
you have already used for PCA and CA. However, if you give the functions explanatory
variables they automatically change to RDA and CCA.

## Example constrained ordination
Let's look at our reindeer-grazed Pine forests that we discussed earlier. This
comes with a large set of potential explanatory variables, about the soil chemistry,
pH etc., stored in the table `varechem` but we will just use a few for simplicity. We can that when we use `head()` and `summary` that we are dealing with a lot of data.

```{r varechem, echo=TRUE}
head(varechem)
summary(varechem)
```

Now the actual analysis using CCA, as you will recall that we had to use CA rather
than PCA for the unconstrained analysis of these data. We will just use potassium (`K`),
phosphorus (`P`), Aluminium (`Al`), soil pH (`pH`), and the amount of bare ground 
(`Baresoil`) as explanatories. We have to think about our response and explanatory variables now but there is something important that we need to understand about how to do the analyses. Our explanatory variables are in the `varechem` dataframe while our response variables are in the `varespec` dataframe. When we do constrained ordination our response in the formula becomes the dataframe storing all our species information while we set the `data = ` argument to where our environmental data are stored. This means that we do the analyses the following way:

```{r varespec_cca, echo = TRUE, eval = FALSE}
# undertake the CCA analyses using a set of explanatory variables
varespec_cca <- cca(varespec ~ K + P + Al + pH + Baresoil, data=varechem)

# first part of the summary output for the CCA
summary(varespec_cca)
```

```{r varespec_cca_sum, echo = FALSE, eval = TRUE}
# undertake the CCA analyses using a set of explanatory variables
varespec_cca <- cca(varespec ~ K + P + Al + pH + Baresoil, data=varechem)

# first part of the summary output for the CCA
summary(varespec_cca)[["cont"]][["importance"]]

```

When you run the `summary()` function on its own you will see a very large amount
of output but it has been simplified for this website. Again, it provides information of the amount of variation
explained by CCA1 (17.7%) and CCA2 (9.3%) so the first two axes explain roughly
27% of the variation.

What are more useful are the plots. The default is a **triplot** which shows
the samples (sites), attributes (species), and explanatory variables (e.g. soil chemistry)
all in one plot. 

**Note**:

* If the explanatory variables are **continuous** (as here) they are shown in the
plot as arrows.
* If the explanatory variables are **categorical** they are shown as points, with
a different point for each of your category levels
* You can of course have a mixture of continuous and categorical variables

```{r varespec_triplot-setup}
varespec_cca <- cca(varespec ~ K + P + Al + pH + Baresoil, data=varechem)
```
```{r varespec_triplot, exercise=TRUE}
plot(varespec_cca)
```


The plot is very cluttered plot, but you can immediately make inferences about the explanatory variables:

* Important explanatory variables have **longer arrows**, less important variables
have **short arrows**
* Two explanatory variables that are **positively correlated** in their effects
will point in the **same** direction
* Two explanatory variables that are **negatively correlated** to each other will
point in **opposite** directions
* Two explanatory variables that are **uncorrelated** with each other will have 
arrows at roughly 90 degrees to each other.

Looking at the explanatory variables above, which statement is correct?

```{r interpret_explanatories}
question("The following are negatively correlated with each other",
         answer("K and P"),
         answer("K and pH"),
         answer("pH and Al"),
         answer("Al and K"),
         answer("P and Al"),
         answer("Al and pH"),
         answer("pH and Baresoil", correct=TRUE),
         random_answer_order = TRUE,
         allow_retry = TRUE)
```

To get a clearer picture of the samples and species, it is generally easier to plot them separately, along with the explanatory variables. Notice that in the commands below, we plot an empty plot first, then the scores and the "biplot arrows" in the third line. We set `display = "bp"` which represents the arrow points for continuous explanatory variables. If you have **categorical** explanatory variables replace these with `display = "cn"` where the`centroids` represents centre for each level of your category. If you have a mixture of **both continuous and categorical** explanatories, you will need to plot each on separate line.

```{r cca_separate_plots-setup}
varespec_cca <- cca(varespec ~ K + P + Al + pH + Baresoil, data=varechem)
```
```{r cca_separate_plots, exercise=TRUE}
# plot the empty ordination space and label the axes with percentage explained
plot(varespec_cca, type = "n", xlab = "CCA1 (17.7%)", ylab = "CCA2 (9.3%)")

# add the site scores
text(varespec_cca, display = "sites", col = "black")

# add the explanatory variables as arrows
points(varespec_cca, display = "bp", head.arrow = 0,
       lwd = 2, pch = 15, cex = 1)

# label the the arrows with the variable names
text(varespec_cca, scaling = 0, display = "bp", head.arrow = 0.1,
     lwd = 2, col= "blue")

# plot the empty ordination space and label the axes with percentage explained
plot(varespec_cca, type = "n", xlab = "CCA1 (17.7%)", ylab = "CCA2 (9.3%)")

# add the site scores
text(varespec_cca, display = "species", col = "red")

# add the explanatory variables as arrows
points(varespec_cca, display = "bp", col = "blue", head.arrow = 0,
       lwd = 2, pch = 15, cex = 1)

# label the the arrows with the variable names
text(varespec_cca, scaling = 0, display = "bp", head.arrow = 0.1,
     lwd = 2, col= "blue")

```

These plots tell you key things about the samples and attributes in relation to
the explanatory variables. For example:

* There is a relatively large amount of bare soil at samples 22, 16, 14, and 
relatively little bare soil at sites 2, 3, 4, 9, 10, 12
* Samples 24, 25, 27, 28 are relatively high in P and K, whilst samples 5, 6, 7
13 and 18 have low P and K
* Al and pH are probably highest in samples 3 and 4
* Species associated with more bare soil include Betupube, Barbhatc, Ptilcili
* Species associated with low K and P include Callvulg, Icmaeric and Vacculig

### Bare soil is not soil chemistry
The longest arrow (and hence most important explanatory variable) is bare soil.
However, this is not of course soil chemistry, and so you might be interested in
looking at what is going on **after** taking into account the effects of bare soil.
This is easy to do with a **partial constrained analysis**. Simply add the term
`Condidition(Baresoil)` to your explanatory variables to remove its effect.

```{r partial_cca, exercise=TRUE}
varespec_cca2 <- cca(varespec ~ K + P + Al + pH + Condition(Baresoil), data=varechem)
plot(varespec_cca2)
```

You can see that once we have "conditioned" for the effects of bare soil, the
relationships between the explanatory variables are much clearer.

### What do the constrained ordination axes mean?
One of the advantages of constrained ordination is that it is much easier to
interpret the axes. For example, looking at the full ordination plot (including
bare soil) you can see that the aluminium arrow (Al) is almost parallel with CCA1 on
the x-axis. Thus we can assume that CCA1 provides an indication that aluminium is influencing community composition,
with low amounts of aluminium at low CCA1 scores, and high amounts at high CCA1 scores.

## Significance tests of constrained ordinations
You can undertake what is known as a **permutation ANOVA** on your constrained
ordination. This is not calculated through the usual method of least squares
(see website explaining linear models). Instead, your attributes data for each sample
are randomly shuffled, and the ordination recalculated. This is done thousands
of times. If your explanatory variables do have a strong effect in your data,
then the real (unrandomised) data will produce a very different ordination from
the permuted (randomised) data. If your explanatory variables have no effect,
then there will be little difference between the real and permuted data.

As with a typical ANOVA you produce F-values and p-values. Note, however,
that as it is based on a randomisation procedure you will get slightly different
results every time you carry out the permutation ANOVA, although the findings
will be roughly the same. If you want to understand more about the detailed
theory (optional) for permutation tests, see the paper by [Legendre et al. (2010)](https://besjournals.onlinelibrary.wiley.com/doi/10.1111/j.2041-210X.2010.00078.x" target="_blank").

### ANOVA of explanatory variables
You can check the importance of the explanatory variables using a `"terms"` 
or `"margin"` options. The `terms` option is most appropriate for a formally designed
experiment, where your explanatory variables include main effects and interaction
terms, for example a laboratory experiment with a balanced number of replicates
in each treatment level. This is analogous to the Type I Sums of Squares in
linear models, and is good for balanced, designed experiments.

However, if you have an **unbalanced** design, the order in which you enter the
explanatory variables into the model affects the results, and it is better to
use the `margin` option. This takes into account potential collinearity (i.e.
correlations) amongst the explanatory variables, and ensures that the order in
which you enter the explanatory variables no longer matters. Collinearity can be a problem when you have two independent explanatory variables which are highly correlated with one another. It can become difficult to understand which explanatory variable is influencing the response variable. It is generally more appropriate
for ecological surveys, such as this one, which are unbalanced.

Run the following code several times. Notice how the exact F- and p-values you
obtain differ slightly; by default it does 999 randomisations of your data,
although you can force it to do more.

```{r varespec_expl_anova-setup}
varespec_cca <- cca(varespec ~ K + P + Al + pH + Baresoil, data=varechem)
```
```{r varespec_expl_anova, exercise=TRUE}
anova(varespec_cca, by="margin")
```

Although the exact p-values will differ slightly each time you run the code, the
overall conclusions are the same, namely that phosphorus (P) and aluminium (Al)
are the two important variables because they have a p-value < 0.05. You will need to report F and p-values in your write up. 

```{r why_not_baresoil}
question("Why is bare soil not significant, even though the arrow is long in
         the CCA plot?",
         answer("Bare soil is a measure of the surface, rather than the below-
                ground soil chemistry", message="No. The ANOVA is not clever
                enough to know how you have sampled the explanatory data"),
         answer("Bare soil is at a 45-degree angle in the plot, therefore is
                not strongly related to any one variable", message="No. Whilst
                bare soil is at a roughly 45-degree angle, this simple implies
                that it is related to both CCA1 and CCA2."),
         answer("Bare soil is collinear with aluminium and the p-value accounts
                for correlations amongst variables", correct=TRUE, message="Good,
                The 'margin' option takes into account collinearities. Bare soil
                is negatively correlated with aluminium (and pH)."),
         answer("The bare soil is related to grazing pressure, which was not
                measured", message="It might or might not be related to grazing
                pressure, but as this was not measured and included in the 
                analysis, it is not relevant to the results of the ANOVA."),
         allow_retry = TRUE)
```

### ANOVA of axes
It is very useful to have a good understanding of the importance of each axis
from your constrained ordination. Whilst the `summary(varespec_cca)` used earlier
returned the percentage variation explained by each axis, sometimes only CCA1 is
worth studying in detail, whilst (rarely) you may have data where CCA1, CCA2 and
even CCA3 need to be checked. You can run a permutation ANOVA on the individual
axes using the `by="axis"` option; again the exact p-values will differ slightly
on each run.

```{r varespec_axis_anova-setup}
varespec_cca <- cca(varespec ~ K + P + Al + pH + Baresoil, data=varechem)
```
```{r varespec_axis_anova, exercise=TRUE}
anova(varespec_cca, by="axis")
```

The first axis is significant so is worth exploring in more detail. The second axes is marginally non-significant because p > 0.05 (p = 0.061 in the table). It would be worth thinking about why the second axes is non-significant because the p-value is slightly > 0.05 - could it be a sample size issue, are these data really noisy, what would happen if we refined our sampling design?

## Constrained ordination with categorical explanatory variables
Let's return to our sand dune dataset, where you will recall that some explanatory
variables were continuous (e.g. depth of the soil A1 horizon `A1`), whilst others
were categorical (e.g. the type of management `Management`, with levels for
biological farming `BF`, hobby farming `HF`, standard farming `SF` and nature
conservation management `NM`). Whilst the analysis of these is identical to before,
the way in which they are displayed in the resultant ordination graph is slightly
different.

You will recall that PCA was appropriate for these data, therefore we will use
the equivalent **linear** constrained technique, redundancy analysis (RDA). The `rda()` function is used for the RDA analysis. As with the CCA, we have our species data in one dataframe as our response and the environmental data in another dataframe which will be our explanatory data. Run the code below, look at the figures and the output.

```{r dune_rda, exercise=TRUE}
# Undertake the RDA with just two explanatory variables
dune_rda <- rda(dune ~ A1 + Management, data=dune.env)

# Plot samples and Management (as point for each level) and A1 (biplot arrow)
plot(dune_rda, type = "n")
text(dune_rda, display ="cn", col = "blue")
text(dune_rda, display = "sites", col = "black")

# Plot species and Management (as point for each level) and A1 (biplot arrow)
plot(dune_rda, type = "n")
text(dune_rda, display ="cn", col = "blue")
text(dune_rda, display = "species", col = "red")

# Anovas of axes and environmental variables
anova(dune_rda, by="axis")
anova(dune_rda, by="margin")
```
Look at the figure first, we can see that the different management groups are plotted in different positions of the plot. ManagementSF is plotted in the middle of sites 3, 4, 8, 9, 12 and 13 so all these sites are likely to managed under the same conditions. The arrow for A1 is pointing in the opposite direction to sites associated with ManagementBF and ManagementHF which would indicate that they are negatively related to A1. If we look at the species plot, Alopgeni and Agrostol are found close to ManagementSF so would suggest that these species are strongly associated with these management conditions.

Notice how the categorical `Management` variable is used. Also note that you
might want to consider renaming `Management` to something shorter, like `mng` so
that the display is clear, since the level names are appended automatically at
the end of the variable name. The names `ManagementBF`, `ManagementNM` etc. are
rather long, and `mngBF`, `mngNM` etc. would be easier to view on the plot.

### Simplifying down to a minimal number of explanatories
When you have a large number of explanatory variables, it can be useful to 
simplify down to a minimal number of key ones, to try and reduce the collinearity
problems that you have just seen. We can do the simplification through multiple `anova()`
tests, dropping the least significant variable, and repeating. Fortunately this
can be done automatically using the `ordistep()` function. You create your
initial constrained ordination with all your explanatory variables, pass it to
`ordistep()` and let it simplify your data. It does produce rather a lot of
output as it grinds through your data, but the end-product is useful.

Let's try it with your `varespec` data, as the `varechem` dataset is very large
with 14 potential explanatory variables. It will generally err on the side of
caution and retain some non-significant explanatory variables. **Note** The 
following code will generate a large amount of output as it steps through all
possible combinations of your explanatory variables. You can include all the environmental variables by using the shortcut ~ . to enter them all without needing to name them separately.

```{r ordistep, exercise=TRUE}
# Create full ordination with all the explanatory variables, using the ~ .
# syntax to save you having to type the names of all 14 variables separately
varespec_bigcca <- cca(varespec ~ . , data=varechem)
varespec_mincca <- ordi_step(varespec_bigcca)

# Check results
anova(varespec_mincca, by="margin")
```

**Key things to think about**

* as there is a large amount of collinearity amongst the variables, none are 
significant when all are included
* Some of the categorical explanatory variables are ordered (ranked) factors;
e.g. `Moisture3` : these are shown with points rather than arrows, and/or
with Q or L subcodes (quadrtic or linear). In your data you are unlikely to
have to deal with these.

The final set of explanatory variables includes four which are significant (p < 0.05) and two that are non-significant. We would report these in our result and produce a plot which contained these explanatory variables.

## Summary

Constrained ordination is a really good way to analyse your data when you have multiple responses in the form of species abundances or coverage (attributes) and explanatory variables in the form of environmental data. There are two commonly used forms of constrained ordination:

* redundancy analysis (RDA) which is used to analyse linear relationships between species and environmental data. This is an extension of PCA.
* canonical correspondence analysis (CCA) which is used to analyse unimodal relationships between species and environmental data. This is an extension of CA.

The explanatory variables can tested to see whether they are significant through the use of a permutation ANOVA.

There is a lot more that you can do with the `vegan` package when it comes to analysing community data. On the R website where the package is hosted, there is more information about the capabilities of `vegan` in the [vignettes section](https://cran.r-project.org/web/packages/vegan/index.html). It is worthwhile having a look at these if you are interested to learn more.

If you want to take a deep dive into ordination methods then the following references will be useful with the Quinn and Keough being a lot more technical:

* [Ramette A(2007) Multivariate analyses in microbial ecology. FEMS Microbiology Ecology;62, 142–160.](https://academic.oup.com/femsec/article/62/2/142/434668)
* Chapter 17 Principal components and correspondence analysis. In Experimental Design and Data Analysis for Biologists by Quinn and Keough. (in library)





