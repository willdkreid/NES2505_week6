---
title: "Constrained analyses"
output: learnr::tutorial
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
library(learnr)
library(mosaic)
library(vegan)
library(bio2020)
data(dune)
data(dune.env)
data(varespec)
data(varechem)
knitr::opts_chunk$set(echo = FALSE)
```


## Multiple responses plus explanatory variables
### Introduction
Unconstrained ordination methods such as PCA, CA and NMDS allow you to summarise
the relationships between your samples (sites, isolates, quadrats etc.) and your
attributes (species, gene sequences etc.). They provide a useful method to 
simplify your data so that it can be viewed in a 2-dimensional ordination plot.
The scores from these plots, especially the first axis, can sometimes be related
to potential explanatory variables to aid interpretation, as you showed with
soil moisture and the dune vegetation analysis.

If you have explanatory variables, you might be tempted to extract an ordination
axis, and after visualising any patterns with a potential explanatory variable,
undertake a linear model, with your chosen **ordination axis** as your response.
For example, recall that you undertook a PCA of the sand dune vegetation data,
and showed a clear pattern with Moisture:

```{r dune_pca, echo=TRUE}
# PCA of dune data
dune_pca <- rda(dune)

# Plot of PC1 vs PC2
plot(dune_pca, type = "n")
text(dune_pca, display = "sites", cex = 0.7)

# Extract PC1 and relate to soil moisture category
dune_pc1 <- scores(dune_pca, display="sites", choices = 1)
gf_boxplot(dune_pc1 ~ Moisture, data=dune.env)%>%
  gf_theme(theme_classic())
```

Now let's do a linear model to formally test the relationship between soil
moisture and dune vegetation composition as described by PC1. We'll display
the ANOVA table, and check the first two model diagnostic plots (residuals and
QQ plots) via the `mplot()` function:

```{r dune_pca_lm, echo=TRUE}
dune_lm <- lm(dune_pc1 ~ Moisture, data=dune.env)
anova(dune_lm)
mplot(dune_lm, which=1:2)

```

The relationship with moisture class is highly significant, with F=14.94426 and
p=6.691419e-05 which is p=0.00006691419 (**remember** you would report these as
"F=14.94, p<0.001"). There are no obvious problems with the residuals vs fitted
plot, with an even scatter around the zero line. The QQ plot looks good, with
most points along the expected diagonal line.

When techniques to handle lots of response variables were first developed, this
was the most common method of analysis. It is sometimes referred to as **indirect gradient analysis**
and was widely used until the 1990's.

## Problems with indirect gradient analysis
The linear model presented on the previous page showed no obvious problems, so
the disadvantages of indirect gradient analysis may not be immediately obvious.
However, one assumption of linear models (and GLMs), is that all your response
data points are independent of each other:

* The composition of plants in your first quadrat should not affect those in your second. 
* The gene sequence from your third isolate should not change those in your fifth
* The bacterial OTU samples from Chile should be independent of the OTUs obtained from France
* The types of insects found in your pitfall trap sample from Northumberland should
not influence those found in your pitfall trap from Cornwall

This seems fairly obvious, and in practical terms, when you collect the data from
field surveys or laboratory experiments, the various samples are independent. The
problem arises from what happens when you undertake an unconstrained ordination.

### Non-independence of ordination scores
Let's repeat our PCA of the sand dune vegetation, but omit one of the samples
at random (sample 6):

```{r compare_pca}
# Multiple plot function from http://www.cookbook-r.com/Graphs/Multiple_graphs_on_one_page_(ggplot2)/ 
#
# ggplot objects can be passed in ..., or to plotlist (as a list of ggplot objects)
# - cols:   Number of columns in layout
# - layout: A matrix specifying the layout. If present, 'cols' is ignored.
#
# If the layout is something like matrix(c(1,2,3,3), nrow=2, byrow=TRUE),
# then plot 1 will go in the upper left, 2 will go in the upper right, and
# 3 will go all the way across the bottom.
#
multi_plot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots==1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}

dune_pca <- rda(dune)
dune_pca_no6 <- rda(dune[-6,])
dune_plt1 <- plot(dune_pca, display="sites", title="PCA with full dataset")
dune_plt2 <- plot(dune_pca_no6, display="sites", title="PCA with one sample omitted")
multi_plot(dune_plt1, dune_plt2, cols=2)
```

You can see that the whole ordination has 'flipped' on its vertical axis. Depending
on your data, sometimes both PC1 and PC2 will flip or rotate. The relative positions
of the samples are still roughly the same, in the samples similar in their species
composition (e.g. 17, 18 and 19) are still relatively close to each other, but they
have nevertheless moved.

**Key point**
Whilst your original quadrats, isolates, samples or sites may have been independent
from each other, once they are converted to PCA axis scores, the actual scores are
**not** independent. Fortunately, an alternative method to resolve this problem,
known as **constrained ordination** was developed in 1989, and has since become
a standard technique for biologists.

## Constrained ordination
In a constrained ordination the explanatory variables (categorical and/or
continuous) are incorporated into the ordination itself. The sample scores are
constrained to be linear combinations of the various explanatory variables,
whilst simultaneously accounting for the composition of the attributes. So the
overall format is:

$$\text{Table of response variables} = \text{Explanatory variables} + \epsilon$$

Note that the technique does not work effectively if you only have one or two
explanatory variables, as it may constrain all your samples or attributes too
much along one axis. The display of constrained analysis is in the form of 
modified ordination plots, which can be very informative once you have learnt
how to interpret them. You can also undertake formal statistical tests using
analyses analogous to ANOVA. The technique will also cope with complex experimental
designs, such as blocked designs, or time-series. You can also create interaction
terms if needed.

Constrained analysis exists in two main forms, linear and unimodal. The linear
form is Redundancy Analysis (RDA) and unimodal is Canonical Correspondence Analysis
(CCA). These are run using the `rda()` and `cca()` functions respectively, which
you have already used for PCA and CA. However, if you give the functions explanatory
variables they automatically change to RDA and CCA.

## Example constrained ordination
Let's look at our reindeer-grazed Pine forests that we discussed earlier. This
comes with a large set of potential explanatory variables, about the soil chemistry,
pH etc., stored in the table `varechem` but we will just use a few for simplicity:

```{r varechem, echo=TRUE}
head(varechem)
summary(varechem)
```

Now the actual analysis, using CCA, as you will recall that we had to use CA rather
than PCA for the unconstrained analysis of these data. We will just use potassium (`K`),
phosphorus (`P`), Aluminium (`Al`), soil pH (`pH`), and the amount of bare ground 
(`Baresoil`) as explanatories. We have to think about our response and explanatory variables now but there is something important that we need to understand about how to do the analyses. Our explanatory variables are in the `varechem` dataframe while our response variables are in the `varespec` dataframe. When we do constrained ordination our response in the formula becomes the dataframe storing all our species information while we set the `data = ` argument to where our environmental data are sorted. This means that we do the analyses the following way:

```{r dune_pca2, echo = TRUE, eval = FALSE}
# undertake the CCA analyses using a set of explanatory variables
varespec_cca <- cca(varespec ~ K + P + Al + pH + Baresoil, data=varechem)

# first part of the summary output for the CCA
summary(varespec_cca)[["cont"]][["importance"]]

```

```{r varespec_cca, echo=FALSE, eval = TRUE}
# undertake the CCA analyses using a set of explanatory variables
varespec_cca <- cca(varespec ~ K + P + Al + pH + Baresoil, data=varechem)

# first part of the summary output for the CCA
summary(varespec_cca)
```

When you run the `summary()` function on its own you will see a very large amount
of output; this is fine in RStudio, but I have simplified it to just the `importance`
measures for this website. Again, it provides information of the amount of variation
explained by CCA1 (17.7%) and CCA2 (9.3%) so the first two axes explain roughly
27% of the variation.

What can be more useful are the plots. The default is a **triplot** which shows
the samples (sites), attributes (species), and explanatory variables (soil chemistry)
all in one plot. Note:

* If the explanatory variables are **continuous** (as here) they are shown in the
plot as arrows.
* If the explanatory variables are **categorical** they are shown as points, with
a different point for each of your category levels
* You can of course have a mixture of continuous and categorical variables

```{r varespec_triplot-setup}
varespec_cca <- cca(varespec ~ K + P + Al + pH + Baresoil, data=varechem)
```
```{r varespec_triplot, exercise=TRUE}
plot(varespec_cca)
```


The plot is very cluttered plot, but you can immediately make inferences about the explanatory variables:

* Important explanatory variables have **longer arrows**, less important variables
have **short arrows**
* Two explanatory variables that are **positively correlated** in their effects
will point in the **same** direction
* Two explanatory variables that are **negatively correlated** to each other will
point in **opposite** directions
* Two explanatory variables that are **uncorrelated** with each other will have 
arrows at roughly 90 degrees to each other.

Looking at the explanatory variables above, which statement is correct?

```{r interpret_explanatories}
question("The following are negatively correlated with each other",
         answer("K and P"),
         answer("K and pH"),
         answer("pH and Al"),
         answer("Al and K"),
         answer("P and Al"),
         answer("Al and pH"),
         answer("pH and Baresoil", correct=TRUE),
         random_answer_order = TRUE,
         allow_retry = TRUE)
```

To get a clearer picture of the samples and species, it is generally easier to plot them separately, along with the explanatory variables. Notice that in the commands below, we plot an empty plot first, then the scores and the "biplot arrows" in the third line. We set `display = "bp"` which represents the "biplot" arrow points for continuous explanatory variables. If you have **categorical** explanatory variables replace these with `display = "cn"` where the`centroids` represents centre for each level of your category. If you have a mixture of **both continuous and categorical** explanatories, you will need to plot each on separate line.

```{r cca_separate_plots-setup}
varespec_cca <- cca(varespec ~ K + P + Al + pH + Baresoil, data=varechem)
```
```{r cca_separate_plots, exercise=TRUE}
# plot the empty ordination space and label the axes with percentage explained
plot(varespec_cca, type = "n", xlab = "CCA1 (17.7%)", ylab = "CCA2 (9.3%)")

# add the site scores
text(varespec_cca, display = "sites", col = "black")

# add the explanatory variables as arrows
points(varespec_cca, display = "bp", head.arrow = 0,
       lwd = 2, pch = 15, cex = 1)

# label the the arrows with the variable names
text(varespec_cca, scaling = 0, display = "bp", head.arrow = 0.1,
     lwd = 2, col= "blue")

# plot the empty ordination space and label the axes with percentage explained
plot(varespec_cca, type = "n", xlab = "CCA1 (17.7%)", ylab = "CCA2 (9.3%)")

# add the site scores
text(varespec_cca, display = "species", col = "red")

# add the explanatory variables as arrows
points(varespec_cca, display = "bp", col = "blue", head.arrow = 0,
       lwd = 2, pch = 15, cex = 1)

# label the the arrows with the variable names
text(varespec_cca, scaling = 0, display = "bp", head.arrow = 0.1,
     lwd = 2, col= "blue")

```

These plots tell you key things about the samples and attributes in relation to
the explanatory variables. For example:

* There is a relatively large amount of bare soil at samples 22, 16, 14, and 
relatively little bare soil at sites 2, 3, 4, 9, 10, 12
* Samples 24, 25, 27, 28 are relatively high in P and K, whilst samples 5, 6, 7
13 and 18 have low P and K
* Al and pH are probably highest in samples 3 and 4
* Species associated with more bare soil include Betupube, Barbhatc, Ptilcili
* Species associated with low K and P include Callvulg, Icmaeric and Vacculig

### Bare soil is not soil chemistry
The longest arrow (and hence most important explanatory variable) is bare soil.
However, this is not of course soil chemistry, and so you might be interested in
looking at what is going on **after** taking into account the effects of bare soil.
This is easy to do with a **partial constrained analysis**. Simply add the term
`Condidition(Baresoil)` to your explanatory variables to remove its effect.

```{r partial_cca, exercise=TRUE}
varespec_cca2 <- cca(varespec ~ K + P + Al + pH + Condition(Baresoil), data=varechem)
plot(varespec_cca, display = "sites")
plot(varespec_cca, display = "species")
```

You can see that once we have "conditioned" for the effects of bare soil, the
relationships between the explanatory variables are much clearer.

**Note**. As there are a large number of attributes in these plots, they are 
still difficult to read. When you use RStudio, change `ordi_plot()` to `geom="points"`
and only label the points away from the centre using `ordi_identify()`. The most 
ubiquitous species in the centre of the plot are of little interest, and do not
need labelling.

### What do the constrained ordination axes mean?
One of the advantages of constrained ordination is that it is much easier to
interpret the axes. For example, looking at the full ordination plot (including
bare soil) you can see that the aluminium arrow (Al) is almost parallel with CCA1 on
the x-axis. Thus we can assume that CCA1 provides some measure of aluminium,
with low amounts at low CCA1 scores, and high amounts at high CCA1 scores.

## Significance tests of constrained ordinations
You can undertake what is known as a **permutation ANOVA** on your constrained
ordination. This is not calculated through the usual method of least squares
(see website explaining linear models). Instead, your sample x attributes data
are randomly shuffled, and the ordination recalculated. This is done thousands
of times. If your explanatory variables do have a strong effect in your data,
then the real (unrandomised) data will produce a very different ordination from
the perumted (randomised) data. If your explanatory variables have no effect,
then there will be little difference between the real and permuted data.

As with a typical ANOVA you produce F-values and p-statistics. Note, however,
that as it is based on a randomisation procedure you will get slightly different
results every time you carry out the permutation ANOVA, although the findings
will be roughly the same. If you want to understand more about the detailed
theory (optional) for permutation tests, see <a href=" https://doi.org/10.1111/j.2041-210X.2010.00078.x" target="_blank">here</a> .

### ANOVA of explanatory variables
You can check the importance of the explanatory variables using a `"terms"` option
or a `"margin"`. The `terms` option is most appropriate for a formally designed
experiment, where your explanatory variables include main effects and interaction
terms, for example a laboratory experiment with a balanced number of replicates
in each treatment level. This is analagous to the Type I Sums of Squares in
linear models, and is good for balanced, designed experiments.

However if you have an **unbalanced** design, the order in which you enter the
explanatory variables into the model affects the results, and it is better to
use the `margin` option. This takes into account potential collinearity (i.e.
correlations) amongst the explanatory variables, and ensures that the order in
which you enter the explanatory variables no longer matters. This is analagous
to the Type III Sums of Squares in linear models. It is generally more appropriate
for ecological surveys, such as this one, which are unbalanced.

Run the following code several times. Notice how the exact F- and p-values you
obtain differ slightly; by default it does 999 randomisations of your data,
although you can force it to do more.

```{r varespec_expl_anova-setup}
varespec_cca <- cca(varespec ~ K + P + Al + pH + Baresoil, data=varechem)
```
```{r varespec_expl_anova, exercise=TRUE}
anova(varespec_cca, by="margin")
```

Although the exact p-values will differ slightly each time you run the code, the
overall conclusions are the same, namely that phosphorus (P) and aluminium (Al)
are the two important variables.

```{r why_not_baresoil}
question("Why is bare soil not significant, even though the arrow is long in
         the CCA plot?",
         answer("Bare soil is a measure of the surface, rather than the below-
                ground soil chemistry", message="No. The ANOVA is not clever
                enough to know how you have sampled the explanatory data"),
         answer("Bare soil is at a 45-degree angle in the plot, therefore is
                not strongly related to any one variable", message="No. Whilst
                bare soil is at a roughly 45-degree angle, this simple implies
                that it is related to both CCA1 and CCA2."),
         answer("Bare soil is collinear with aluminium and the p-value accounts
                for correlations amongst variables", correct=TRUE, message="Good,
                The 'margin' option takes into account collinearities. Bare soil
                is negatively correlated with aluminium (and pH)."),
         answer("The bare soil is related to grazing pressure, which was not
                measured", message="It might or might not be related to grazing
                pressure, but as this was not measured and included in the 
                analysis, it is not relevant to the results of the ANOVA."),
         allow_retry = TRUE)
```

### ANOVA of axes
It is very useful to have a good understanding of the importance of each axis
from your constrained ordination. Whilst the `summary(varespec_cca)` used earlier
returned the percentage variation explained by each axis, sometimes only CCA1 is
worth studying in detail, whilst (rarely) you may have data where CCA1, CCA2 and
even CCA3 need to be checked. You can run a permutation ANOVA on the individual
axes using the `by="axis"` option; again the exact p-values will differ slightly
on each run.

```{r varespec_axis_anova-setup}
varespec_cca <- cca(varespec ~ K + P + Al + pH + Baresoil, data=varechem)
```
```{r varespec_axis_anova, exercise=TRUE}
anova(varespec_cca, by="axis")
```

## Constrained ordination with categorical explanatory variables
Let's return to our sand dune dataset, where you will recall that some explanatory
variables were continuous (e.g. depth of the soil A1 horizon `A1`), whilst others
were categorical (e.g. the type of management `Management`, with levels for
biological farming `BF`, hobby farming `HF`, standard farming `SF` and nature
conservation management `NM`). Whilst the analysis of these is identical to before,
the way in which they are displayed in the resultant ordination graph is slightly
different.

You will recall that PCA was appropriate for these data, therefore we will use
the equivalent **linear** constrained technique, redundancy analysis (RDA). This
is called via the `ordi_rda()` function from the `bio2020` library. 

After running the code below, modify it to test the significance of the individual
axes and variables, and extend the x-axis range on the species plot so that it
is easier to read the `Management` variables.

**Hints**:

* Pipe your `ordi_plot` via the `%>%` symbol into `gf_lims()` to extend the x-axis
* Use the `anova()` function with the `by=` option set correctly

```{r dune_rda, exercise=TRUE}
# Undertake the RDA with just two explanatory variables
dune_rda <- rda(dune ~ A1 + Management, data=dune.env)

# Plot samples and Management (as point for each level) and A1 (biplot arrow)
plot(dune_rda, geom="text", layers=c("sites", "centroids", "biplot"))

# Plot species and explanatories. Add "arrows=FALSE" to reduce clutter
plot(dune_rda, geom="text", layers=c("species", "centroids", "biplot"))
```
```{r dune_rda-solution}
# Undertake the RDA with just two explanatory variables
dune_rda <- ordi_rda(dune ~ A1 + Management, data=dune.env)

# Plot samples and Management (as point for each level) and A1 (biplot arrow)
ordi_plot(dune_rda, geom="text", layers=c("sites", "centroids", "biplot"))

# gf_lims extends the x-axis
ordi_plot(dune_rda, geom="text", layers=c("species", "centroids", "biplot")) %>% 
  gf_lims(x=c(-2.5, 3)) 

# Anovas of axes and environmental variables
anova(dune_rda, by="axis")
anova(dune_rda, by="margin")
```

Notice how the categorical `Management` variable is used. Also note that you
might want to consider renaming `Management` to something shorter, like `mng` so
that the display is clear, since the level names are appended automatically at
the end of the variable name. The names `ManagementBF`, `ManagementNM` etc. are
rather long, and `mngBF`, `mngNM` etc. would be easier to view on the plot.

**Hints**:

* You can automatically include all the explanatory variables by using ` ~ .` on
the equation formula

```{r dune_rda2, exercise=TRUE}
# Add code to include all the explanatory variables, and check with anova
```
```{r dune_rda2-solution}
# Include all the environmental variables; Note use of shortcut ~ . to enter
# all the explanatories without needing to name them separately
dune_rda2 <- ordi_rda(dune ~ ., data=dune.env)

# Plots
ordi_plot(dune_rda2, geom="text", layers=c("sites", "centroids", "biplot"))
ordi_plot(dune_rda2, geom="text", layers=c("species", "centroids", "biplot"))

anova(dune_rda2, by="margin")
```

**Note**

* as there is a large amount of collinearity amongst the variables, none is 
significant when all are included
* Some of the categorical explanatory variables are ordered (ranked) factors;
e.g. `Moisture3` : these are shown with points rather than arrows, and/or
with Q or L subcodes (quartic or linear). In your data you are unlikely to
have to deal with these.

### Simplifying down to a minimal number of explanatories
When you have a large number of explanatory variables, it can be useful to 
simplify down to a minimal number of key ones, to try and reduce the collinearity
problems that you have just seen. This can be done through multiple `anova()`
tests, dropping the least significant variable, and repeating. Fortunately this
can be done automatically using the `ordistep()` function. You create your
initial constrained ordination with all your explanatory variables, pass it to
`ordistep()` and let it simplify your data. It does produce rather a lot of
output as it grinds through your data, but the end-product is useful.

Let's try it with your `varespec` data, as the `varechem` dataset is very large
with 14 potential explanatory variables. It will generally err on the side of
caution and retain some non-significant explanatory variables. **Note** The 
following code will generate a large amount of output as it steps through all
possible combinations of your explanatory variables.

```{r ordistep, exercise=TRUE}
# Create full ordination with all the explanatory variables, using the ~ .
# syntax to save you having to type the names of all 14 variables separately
varespec_bigcca <- ordi_cca(varespec ~ . , data=varechem)
varespec_mincca <- ordi_step(varespec_bigcca)

# Check results
anova(varespec_mincca, by="margin")
```


